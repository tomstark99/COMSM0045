{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto differentiation: PyTorch's autograd\n",
    "\n",
    "\n",
    "One of the key differences between PyTorch and numpy is the inclusion of an auto differentiation framework, which allows you to track the sequence of operations applied to a tensor and compute the derivatives of the output of the sequence of operations with respect to the input. To achieve this, PyTorch builds a computational graph as you apply operations of tensors tracking the inputs that produced an output.\n",
    "\n",
    "To train a network, we alternate between two steps over and over again until our network converges. First we compute a *forward pass* which propagates the values input into the network to the output. Second, we go back through the graph propagating gradients from the output of the network back to the input. These gradients are computed with respect to a loss function that we wish to minimize. As we pass back through the network propagating gradients we update the weights of the network in the direction of the negative gradient so as to reduce the loss. The gradients are computed using extensive use of the [chain rule](https://en.wikipedia.org/wiki/Chain_rule) in a method called [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) (AD). We break down the gradient of the loss function with respect to a weight in the network into the product of many partial derivatives by the chain rule. The automatic differentiation support in PyTorch does this (almost) transparently.\n",
    "\n",
    "To be able to compute derivatives of a sequence of operations, we have to tell PyTorch that we want to track the operations applied to the input tensor which enables it to track the operations applied.\n",
    "\n",
    "We'll take a look at a very simple computational graphy computing the expression $z = ((x + 2) \\times 2) / 5$. The computational graph corresponding to this expression looks like this:\n",
    "\n",
    "![computational graph](./media/computation-graph.png)\n",
    "\n",
    "Now we can do a forward pass through the computational graph to compute $z$ computing all the intermediate values.\n",
    "\n",
    "![computational graph - forward pass](./media/computation-graph-forward.png)\n",
    "\n",
    "If we look at each individual operation in isolation, we can define the partial derivatives of the inputs to the operation with respect to the output. Later we will chain these together to compute $\\frac{dz}{dx}$.\n",
    " \n",
    "$$f_+(x_1, x_2) = x_1 + x_2$$\n",
    "$$f_\\times(x_1, x_2) = x_1 \\times x_2$$\n",
    "$$f_/(x_1, x_2) = x_1 / x_2$$\n",
    "\n",
    "$$\\frac{\\partial f_+(x_1, x_2)}{\\partial x_1} = 1$$\n",
    "$$\\frac{\\partial f_+(x_1, x_2)}{\\partial x_1} = 1$$\n",
    "\n",
    "$$\\frac{\\partial f_\\times(x_1, x_2)}{\\partial x_1} = x_2$$\n",
    "$$\\frac{\\partial f_\\times(x_1, x_2)}{\\partial x_2} = x_1$$\n",
    "\n",
    "$$\\frac{\\partial f_/(x_1, x_2)}{\\partial x_1} = \\frac{1}{x_2}$$\n",
    "$$\\frac{\\partial f_/(x_1, x_2)}{\\partial x_2} = x_1$$\n",
    "\n",
    "Using these, we can compute the derivates along the edges of a path from the output of the network back to the input using the chain rule: $$\\frac{dy}{dx} = \\frac{dy}{dz} \\frac{dz}{dx}$$. As we trace the path from the output, we compute the gradient of the edge, as we pass a node and move onto a new edge, we compute the gradient of the node's output with respect to its input and then multiply that by the incoming gradient (i.e. we're accumulating the gradient along the path, this is like computing the chain rule in little steps). \n",
    "\n",
    "![computational graph - backward pass](./media/computation-graph-backward.png)\n",
    "\n",
    "Note how we've only computed the gradients along the path back to the single input $x$. This is because the other values are constant and so their gradient is of now interest to use. If $x$ were a weight in a neural network, we'd use the gradient to update the weight. \n",
    "\n",
    "If we expand the expression and compute it's derivative in one fell swoop we can check the AD result\n",
    "\n",
    "$$z = ((x + 2) \\times 2) / 5 = \\frac{2x}{5} + \\frac{4}{5}$$\n",
    "$$\\frac{dz}{dx} = \\frac{2}{5}$$\n",
    "\n",
    "Which is exactly what we got using AD. AD is just a way of breaking up the process into little steps which make it amenable to computation like implemented in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8000, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(1.0, requires_grad=True)  # We will use a scalar tensor for simplicity here. \n",
    "z0 = x * 2\n",
    "z1 = z0 + 2\n",
    "z2 = z1 / 5\n",
    "z2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `z2` has a `grad_fn` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DivBackward0 at 0x7f85b81f98d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2.grad_fn  # corresponds to dz/dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to the function that computes the derivative of `z2` with respect to `z1`. Additionally, the `grad_fn` also holds a pointer to the previous operation in the sequence of operations used to construct `z`, we can go back through the chain to see how the gradients are transformed. computation graph tracing from the output of our expression `z2` back to the input `x`, one operation at time. Each `grad_fn` takes in the gradient from the operation ahead of it, transforms it, and passes it to the function before it (remember, we're going backward through the computation graph during gradient computation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7f858214d810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corresponds to dz2/dz1\n",
    "z2.grad_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x7f858214dfd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corresponds to dz1/dz0, basically an identity function\n",
    "z2.grad_fn.next_functions[0][0].next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AccumulateGrad at 0x7f858216b610>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the computational graph is complete, there are no further functions\n",
    "# on the backward chain as we have reach an input node in the computational tree.\n",
    "# This simply accumulates gradients\n",
    "z2.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No more partial derivatives along the chain.\n",
    "z2.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0].next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can compute input_grad * dz2/dz1 \n",
    "input_grad = torch.tensor(1.)\n",
    "z2.grad_fn(input_grad)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we can compute input_grad * dz1/dz0\n",
    "z1.grad_fn(input_grad)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we can compute input_grad * dz0/dx\n",
    "z0.grad_fn(input_grad)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining these we can get input_grad * dz/dx = input_grad * dz/dy * dy/dx \n",
    "# (by the chain rule)\n",
    "\n",
    "z0.grad_fn(z1.grad_fn(z2.grad_fn(input_grad)[0])[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before applying grad_fn: tensor(1.)\n",
      "grad_fn: <DivBackward0 object at 0x7f85b81f98d0>\n",
      "after applying grad_fn: tensor(0.2000)\n",
      "\n",
      "before applying grad_fn: tensor(0.2000)\n",
      "grad_fn: <AddBackward0 object at 0x7f858214d810>\n",
      "after applying grad_fn: tensor(0.2000)\n",
      "\n",
      "before applying grad_fn: tensor(0.2000)\n",
      "grad_fn: <MulBackward0 object at 0x7f858214dfd0>\n",
      "after applying grad_fn: tensor(0.4000)\n",
      "\n",
      "before applying grad_fn: tensor(0.4000)\n",
      "grad_fn: <AccumulateGrad object at 0x7f858216b610>\n"
     ]
    }
   ],
   "source": [
    "# Or we can do this in a more general way tracing back from the output\n",
    "# of the expression to the input\n",
    "grad_fn = z2.grad_fn\n",
    "grad = torch.tensor(1.)\n",
    "while True:\n",
    "    print(\"before applying grad_fn:\", grad)\n",
    "    print(\"grad_fn:\", grad_fn)\n",
    "    grad = grad_fn(grad)\n",
    "    if len(grad) > 0:\n",
    "        grad = grad[0]\n",
    "    else:\n",
    "        break\n",
    "    print(\"after applying grad_fn:\", grad)\n",
    "    print()\n",
    "    grad_fn = grad_fn.next_functions[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
